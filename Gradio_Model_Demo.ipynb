{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fYsM_cV8JSsA"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "\n",
        "import keras.layers as layers\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import Model\n",
        "from numpy import argmax\n",
        "from keras.optimizers import SGD, Adam\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator # In Colab, change to keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import gradio as gr\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "NaJ-7vHQsQTW",
        "outputId": "d05874d4-5dc5-4e3b-d76e-af6ed67b2a18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 1 variables whereas the saved optimizer has 12 variables. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://84c8627ac27b61d9eb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://84c8627ac27b61d9eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CREATE GRADIO INTERFACE\n",
        "\n",
        "IMAGE_SIZE=(224,224) # images will be resized to this\n",
        "def build_and_compile_cnn():\n",
        "    \"\"\"\n",
        "    Build and compile a Convolutional Neural Network model.\n",
        "\n",
        "    The CNN consists of:\n",
        "    - Three convolutional layers with ReLU activation and max pooling layers.\n",
        "    - A flattening layer to convert 2D matrices into a 1D vector.\n",
        "    - A dense (fully connected) layer with ReLU activation.\n",
        "    - A dense output layer with sigmoid activation for binary classification.\n",
        "\n",
        "    The model is compiled using the RMSProp optimizer and binary cross-entropy loss.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): The compiled CNN model.\n",
        "    \"\"\"\n",
        "    # Initialize a sequential model\n",
        "    model = Sequential([\n",
        "        # 1: convolutional layer with 32 filters of size 3x3, ReLU activation, and a max pooling layer with window size 2x2\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        # 2: convolutional layer with 64 filters of size 3x3, ReLU activation, and a max pooling layer with window size 2x2\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        # 3: convolutional layer with 64 filters of size 3x3, ReLU activation, and a max pooling layer with window size 2x2\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        # 4: flatten pixels of resulting image into a 1D vector\n",
        "        layers.Flatten(),\n",
        "        # 5: feed result into fully connected dense layer with 64 units and ReLU activation\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        # 6. output layer with a single unit and sigmoid activation for binary classification\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # optimizerAdam = Adam(learning_rate=ALPHA) # RMSProp gives much better results\n",
        "    # Use binary cross-entropy loss function and RMSProp optimizer\n",
        "    model.compile(loss='binary_crossentropy', optimizer='RMSProp', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create a new instance of the raw model by loading saved weights\n",
        "raw_model = build_and_compile_cnn()\n",
        "raw_model.load_weights('16_epochs.weights.h5')\n",
        "\n",
        "# Select 10 Reptile and Amphibian images to show in the Gradio interface\n",
        "def get_sample_image_paths():\n",
        "    \"\"\"\n",
        "    Get sample reptile/amphibian images.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of image paths.\n",
        "    \"\"\"\n",
        "    # State location of image directory\n",
        "    dir = \"Gradio_Sample_Images\"\n",
        "\n",
        "    # Fetch paths of images\n",
        "    images = [os.path.join(dir, f) for f in os.listdir(dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "    return images\n",
        "\n",
        "# Create function for Gradio interface\n",
        "def classify_image_raw_model(inp):\n",
        "    \"\"\"\n",
        "    Classify an input image as either 'Amphibian' or 'Reptile' using the raw CNN Model.\n",
        "\n",
        "    Args:\n",
        "        inp (PIL.Image): The input image to classify.\n",
        "\n",
        "    Returns:\n",
        "        str: The classification result ('Amphibian' or 'Reptile').\n",
        "    \"\"\"\n",
        "    # Resize and normalize input image\n",
        "    inp = inp.resize(IMAGE_SIZE)\n",
        "    inp = np.array(inp) / 255.0\n",
        "    inp = inp.reshape((-1, 224, 224, 3))\n",
        "\n",
        "    # Predict class\n",
        "    prediction = raw_model.predict(inp)\n",
        "    predicted_class = int(np.round(prediction[0][0]))\n",
        "\n",
        "    # Map class index to class name\n",
        "    class_names = {0: 'Amphibian', 1: 'Reptile'}\n",
        "    return class_names[predicted_class]\n",
        "\n",
        "def classify_image_ensemble_model(inp):\n",
        "    \"\"\"\n",
        "    Classify an input image as either 'Amphibian' or 'Reptile' using the ensembled pre-trained CNN model.\n",
        "\n",
        "    Args:\n",
        "        inp (PIL.Image): The input image to classify.\n",
        "\n",
        "    Returns:\n",
        "        str: The classification result ('Amphibian' or 'Reptile').\n",
        "    \"\"\"\n",
        "    # Resize and normalize input image\n",
        "    inp = inp.resize(IMAGE_SIZE)\n",
        "    inp = np.array(inp) / 255.0\n",
        "    inp = inp.reshape((-1, 224, 224, 3)) # For this function, replace any of these to fit the pre-trained model params\n",
        "\n",
        "    # Predict class\n",
        "    prediction = raw_model.predict(inp) # For this function, replace this with the ensemble model\n",
        "    predicted_class = int(np.round(prediction[0][0]))\n",
        "\n",
        "    # Map class index to class name\n",
        "    class_names = {0: 'Amphibian', 1: 'Reptile'}\n",
        "    return class_names[predicted_class]\n",
        "\n",
        "def classify_images(inp):\n",
        "    \"\"\"\n",
        "    Classify an input image using both models and return both results.\n",
        "\n",
        "    Args:\n",
        "        inp (PIL.Image): The input image to classify.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[str, str]: The classification results from both models.\n",
        "    \"\"\"\n",
        "    return classify_image_raw_model(inp), classify_image_ensemble_model(inp)\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=classify_images,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=1, label=\"Raw Classifier\"),\n",
        "        gr.Label(num_top_classes=1, label=\"Ensembled Pre-trained Classifier\")\n",
        "    ],\n",
        "    examples=get_sample_image_paths(),\n",
        "    title=\"Amphibian vs Reptile Classifier\",\n",
        "    description=\"Upload an image to classify it as either an Amphibian or a Reptile.\"\n",
        ")\n",
        "interface.launch(share=True)\n",
        "\n",
        "# The raw model accurately predicts 9/10 Gradio image examples. It incorrectly classifies one reptile as an amphibian"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
