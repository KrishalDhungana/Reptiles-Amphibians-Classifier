{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "INCLUDE ALL NECESSARY IMPORTS AND FUNCTIONS\n",
    "'''\n",
    "import keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Model\n",
    "from numpy import argmax\n",
    "from keras.optimizers import SGD\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "IMAGE_SIZE=(300,300)\n",
    "ALPHA=0.01\n",
    "NUM_EPOCHS=5\n",
    "\n",
    "def prepareDataOld():\n",
    "  alpha=0.01\n",
    "  num_epochs=5\n",
    "  batch_size=32\n",
    "  image_size=(300,300)\n",
    "  #MAKE DF WITH IMAGE PATHS AND IMAGE LABELS\n",
    "  image_dir = Path(\"reptiles-and-amphibians-image-dataset\")\n",
    "  filepaths = list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))\n",
    "  labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "  filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "  labels = pd.Series(labels, name='Label')\n",
    "  image_df = pd.concat([filepaths, labels], axis=1)\n",
    "  \n",
    "  train = ImageDataGenerator(\n",
    "    rescale=1/255\n",
    "  )\n",
    "  validation = ImageDataGenerator(\n",
    "    rescale=1/255\n",
    "  )\n",
    "  train_dataset = train.flow_from_directory('reptiles-and-amphibians-image-dataset', target_size={300,300}, batch_size=32, class_mode='binary')\n",
    "  return\n",
    "\n",
    "\n",
    "def prepareData():\n",
    "  # CREATE DF WITH IMAGE PATHS AND IMAGE LABELS\n",
    "  image_dir = Path(\"reptiles-and-amphibians-image-dataset\")\n",
    "  filepaths = list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))\n",
    "  labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "  filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "  labels = pd.Series(labels, name='Label')\n",
    "  image_df = pd.concat([filepaths, labels], axis=1)\n",
    "  train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=13)\n",
    "\n",
    "  train_generator = ImageDataGenerator(\n",
    "      rescale=1./255, #normalize pixel values from 0-255 to 0-1\n",
    "      validation_split=0.2 #20% of training data will be used as validation\n",
    "  )\n",
    "  test_generator = ImageDataGenerator(\n",
    "      rescale=1./255\n",
    "  )\n",
    "  # CREATE DATA GENERATORS FOR TRAINING, VALIDATION, AND TESTING SETS\n",
    "  train = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=IMAGE_SIZE, #resize all images to size 300x300\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "  val = train_generator.flow_from_dataframe(\n",
    "      dataframe=train_df,\n",
    "      x_col='Filepath',\n",
    "      y_col='Label',\n",
    "      target_size=IMAGE_SIZE,\n",
    "      color_mode='rgb',\n",
    "      class_mode='categorical',\n",
    "      batch_size=32,\n",
    "      shuffle=True,\n",
    "      seed=42,\n",
    "      subset='validation'\n",
    "  )\n",
    "  test = test_generator.flow_from_dataframe(\n",
    "      dataframe=test_df,\n",
    "      x_col='Filepath',\n",
    "      y_col='Label',\n",
    "      target_size=IMAGE_SIZE,\n",
    "      color_mode='rgb',\n",
    "      class_mode='categorical',\n",
    "      batch_size=32,\n",
    "      shuffle=False\n",
    "  )\n",
    "  return train, val, test\n",
    "\n",
    "def build_and_compile_cnn():\n",
    "    model = Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(300,300,3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    sgd_optimizer = SGD(learning_rate=ALPHA)\n",
    "    model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_cnn(model, train_generator, validation_generator):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "def evaluate_model(model, generator):\n",
    "    loss, accuracy = model.evaluate(generator)\n",
    "    return loss, accuracy\n",
    "\n",
    "def create_confusion_matrix(model, generator):\n",
    "    y_pred = model.predict(generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = generator.classes\n",
    "    confusion_matrix_result = confusion_matrix(y_true, y_pred_classes)\n",
    "    return confusion_matrix_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3868 validated image filenames belonging to 10 classes.\n",
      "Found 967 validated image filenames belonging to 10 classes.\n",
      "Found 1209 validated image filenames belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  kernel_regularizer=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  def workers(self):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 89/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.2941 - loss: 2.1233"
     ]
    }
   ],
   "source": [
    "train, val, test = prepareData()\n",
    "model = build_and_compile_cnn()\n",
    "history = train_and_evaluate_cnn(model, train, val)\n",
    "'''\n",
    "train_loss, train_accuracy = evaluate_model(model, train)\n",
    "validation_loss, validation_accuracy = evaluate_model(model, val)\n",
    "test_loss, test_accuracy = evaluate_model(model, test)\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(f\"Validation Accuracy: {validation_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix_result = create_confusion_matrix(model, test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix_result)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
